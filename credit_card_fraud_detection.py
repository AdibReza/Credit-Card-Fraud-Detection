# -*- coding: utf-8 -*-
"""Credit card fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G6L3dClVp_TWpfJEL-3_DFQWrp12biqS
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

card_dataset = pd.read_csv('/content/drive/MyDrive/ML datasets/Credit card fraud detection/creditcard.csv')
card_dataset.head()

#as credit card informations are confidential, all of the column names are hidden.

card_dataset.tail()

card_dataset.info()

# its a huugeeee dataset. Biggest I've done.

#checking the number of missing values
card_dataset.isnull().sum()

card_dataset['Class'].value_counts()

# Our data is highly imbalanced.
# 0----> Normal transaction
# 1----> Fraudulent transaction

"""We will now seperate normal transaction and fraudulent transadtion into two variables."""

legit = card_dataset[card_dataset.Class == 0]
fraud = card_dataset[card_dataset.Class == 1]

#Stratistical measures of the datas
legit.Amount.describe()

#We are doing this because of the imbalance. we are trying to find a fault or difference between the two datas.

fraud.Amount.describe()

"""OKay so as there is a difference in the mean of the two values, we will analyze these."""

card_dataset.groupby('Class').mean()

legit_sample = legit.sample(n = 492)

"""Concatenating two dataset"""

new_dataset = pd.concat([legit_sample, fraud], axis = 0)

new_dataset.head()

new_dataset.info()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

# the pattern is still there and thats good

x = new_dataset.drop('Class', axis =1)
y = new_dataset['Class']

print(x.shape, y.shape)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 2)

"""Logistic Regression"""

model = LogisticRegression()
model.fit(x_train,y_train)

#training data prediction
training_data_prediction = model.predict(x_train)
accuracy = accuracy_score(training_data_prediction, y_train)
print(accuracy)

#test data prediction
test_data_prediction = model.predict(x_test)
accuracy = accuracy_score(test_data_prediction, y_test)
print(accuracy)

